import streamlit as st
import ollama
import base64
from textblob import TextBlob
import nltk
from datetime import datetime
import pandas as pd
import time
import speech_recognition as sr  # SpeechRecognition module for voice input

# Download NLTK data for sentiment analysis
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

# Set page config
st.set_page_config(page_title="Mental Health Chatbot", layout="wide")

# Background setup
def get_base64(background):
    try:
        with open(background, "rb") as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except Exception as e:
        st.error(f"Error loading background image: {e}")
        return ""

bin_str = get_base64("background.png")

st.markdown(f"""
    <style>
        .stApp {{
            background-image: url("data:image/png;base64,{bin_str}");
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
            background-attachment: fixed;
        }}
        .chat-box {{
            max-height: 500px;
            overflow-y: auto;
            margin-bottom: 20px;
            padding: 15px;
            background: rgba(255, 255, 255, 0.9);
            border-radius: 10px;
        }}
    </style>
""", unsafe_allow_html=True)

# Initialize session state
st.session_state.setdefault('conversation_history', [])
st.session_state.setdefault('mood_history', [])
st.session_state.setdefault('current_mood', 'neutral')

# NLP Functions
def analyze_sentiment(text):
    analysis = TextBlob(text)
    polarity = analysis.sentiment.polarity
    if polarity < -0.5:
        return "üòî Stressed"
    elif polarity < 0:
        return "üòü Sad"
    elif polarity < 0.5:
        return "üòä Calm"
    else:
        return "üòÑ Happy"

# Mental Health Features
def track_mood(mood):
    st.session_state.mood_history.append({
        "mood": mood,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    })

def breathing_exercise():
    return """üå¨Ô∏è 4-7-8 Breathing Technique:
1. Empty your lungs completely
2. Breathe in quietly through nose for 4 seconds
3. Hold breath for 7 seconds
4. Exhale completely through mouth for 8 seconds
5. Repeat 4 times"""

def mental_health_resources():
    return """üìö Helpful Resources:
‚Ä¢ Crisis Hotline: 1-800-273-TALK (8255)
‚Ä¢ Anxiety & Depression Association of America: adaa.org
‚Ä¢ National Suicide Prevention Lifeline: 988lifeline.org
‚Ä¢ Calm Meditation App: calm.com
‚Ä¢ Headspace Meditation: headspace.com"""

# Enhanced Response Generation
def generate_response(user_input):
    # Analyze sentiment
    mood = analyze_sentiment(user_input)
    track_mood(mood)
    st.session_state.current_mood = mood
    
    # Add context to prompt
    context = f"User mood detected as {mood}. Respond with empathy and emotional support."
    full_prompt = f"{context}\nUser: {user_input}"
    
    st.session_state.conversation_history.append({"role": "user", "content": full_prompt})
    
    response = ollama.chat(model="llama3:8b", messages=st.session_state.conversation_history)
    ai_response = response['message']['content']
    
    st.session_state.conversation_history.append({"role": "assistant", "content": ai_response})
    return ai_response

# Define the functions for affirmation and meditation guide
def generate_affirmation():
    prompt = f"Provide a positive affirmation for someone feeling {st.session_state.current_mood}"
    response = ollama.chat(model="llama3:8b", messages=[{"role": "user", "content": prompt}])
    return response['message']['content']

def generate_meditation_guide():
    prompt = f"Create a 5-minute guided meditation script for someone feeling {st.session_state.current_mood}"
    response = ollama.chat(model="llama3:8b", messages=[{"role": "user", "content": prompt}])
    return response['message']['content']

# Function to listen to the microphone and convert speech to text
def listen_to_microphone():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("Listening... Please speak now.")
        audio = recognizer.listen(source)
        try:
            text = recognizer.recognize_google(audio)
            st.success(f"You said: {text}")
            return text
        except sr.UnknownValueError:
            st.error("Sorry, I did not understand that. Please try again.")
        except sr.RequestError:
            st.error("Could not request results from Google Speech Recognition service.")
    return None

# UI Components
st.title("Mental Health Support Agent üåà")

# Sidebar for additional features
with st.sidebar:
    st.header("Additional Features")
    
    # Mood Tracking
    with st.expander("Track Your Mood"):
        mood = st.selectbox("How are you feeling?", ["üòÑ Happy", "üòä Calm", "üòü Sad", "üòî Stressed"])
        if st.button("Log Mood"):
            track_mood(mood)
            st.success("Mood logged successfully!")
    
    # Breathing Exercises
    if st.button("üßò Breathing Exercise"):
        st.info(breathing_exercise())
    
    # Mental Health Resources
    if st.button("üìö Get Resources"):
        st.info(mental_health_resources())

# Main Chat Interface
with st.container():
    st.subheader("Chat Interface")
    
    # Chat history
    with st.container():
        st.markdown("<div class='chat-box'>", unsafe_allow_html=True)
        for msg in st.session_state.conversation_history:
            role = "user" if msg['role'] == "user" else "assistant"
            with st.chat_message(role):
                st.write(msg['content'])
        st.markdown("</div>", unsafe_allow_html=True)
    
    # User input via text or microphone
    user_message = st.chat_input("How can I help you today?")
    
    if user_message:
        with st.spinner("Analyzing and responding..."):
            ai_response = generate_response(user_message)
            with st.chat_message("assistant"):
                st.write(ai_response)
                st.caption(f"Detected Mood: {st.session_state.current_mood}")
    
    # Listen via microphone button
    if st.button(""):
        speech_input = listen_to_microphone()
        if speech_input:
            ai_response = generate_response(speech_input)
            with st.chat_message("assistant"):
                st.write(ai_response)
                st.caption(f"Detected Mood: {st.session_state.current_mood}")
    
    # Clear Chat Button (added to the main chat interface)
    if st.button("üßπ Clear Chat"):
        st.session_state.conversation_history = []  # Clears the conversation history
        st.session_state.mood_history = []  # Clears the mood history
        st.rerun()  # Refreshes the app

# Mood Tracking Visualization
if st.session_state.mood_history:
    with st.expander("View Mood History"):
        mood_df = pd.DataFrame(st.session_state.mood_history)
        mood_df['timestamp'] = pd.to_datetime(mood_df['timestamp'])
        
        # Count occurrences of each mood and plot as a bar chart
        mood_counts = mood_df['mood'].value_counts()
        st.bar_chart(mood_counts)

# Action Buttons
with st.container():
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üåü Get Affirmation"):
            affirmation = generate_affirmation()
            st.info(f"**Affirmation:** {affirmation}")
    
    with col2:
        if st.button("üßò Guided Meditation"):
            meditation_guide = generate_meditation_guide()
            st.info(f"**Meditation Guide:** {meditation_guide}")
    
    with col3:
        if st.button("‚ÑπÔ∏è Current Mood"):
            st.info(f"Your current mood: {st.session_state.current_mood}")


# import streamlit as st
# import ollama
# import base64
# from textblob import TextBlob
# import nltk
# from datetime import datetime
# import pandas as pd
# import time
# import speech_recognition as sr  # SpeechRecognition module for voice input

# # Download NLTK data for sentiment analysis
# try:
#     nltk.data.find('tokenizers/punkt')
# except LookupError:
#     nltk.download('punkt')

# # Set page config
# st.set_page_config(page_title="Mental Health Chatbot", layout="wide")

# # Background setup
# def get_base64(background):
#     try:
#         with open(background, "rb") as f:
#             data = f.read()
#         return base64.b64encode(data).decode()
#     except Exception as e:
#         st.error(f"Error loading background image: {e}")
#         return ""

# bin_str = get_base64("background.png")

# st.markdown(f"""
#     <style>
#         .stApp {{
#             background-image: url("data:image/png;base64,{bin_str}");
#             background-size: cover;
#             background-position: center;
#             background-repeat: no-repeat;
#             background-attachment: fixed;
#         }}
#         .chat-box {{
#             max-height: 500px;
#             overflow-y: auto;
#             margin-bottom: 20px;
#             padding: 15px;
#             background: rgba(255, 255, 255, 0.9);
#             border-radius: 10px;
#         }}
#         /* Custom Microphone Button Styles */
#         .microphone-button {{
#             font-size: 24px;
#             background-color: transparent;
#             border: none;
#             cursor: pointer;
#         }}
#         .microphone-button img {{
#             width: 40px;
#             height: 40px;
#         }}
#     </style>
# """, unsafe_allow_html=True)

# # Initialize session state
# st.session_state.setdefault('conversation_history', [])
# st.session_state.setdefault('mood_history', [])
# st.session_state.setdefault('current_mood', 'neutral')

# # NLP Functions
# def analyze_sentiment(text):
#     analysis = TextBlob(text)
#     polarity = analysis.sentiment.polarity
#     if polarity < -0.5:
#         return "üòî Stressed"
#     elif polarity < 0:
#         return "üòü Sad"
#     elif polarity < 0.5:
#         return "üòä Calm"
#     else:
#         return "üòÑ Happy"

# # Mental Health Features
# def track_mood(mood):
#     st.session_state.mood_history.append({
#         "mood": mood,
#         "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
#     })

# def breathing_exercise():
#     return """üå¨Ô∏è 4-7-8 Breathing Technique:
# 1. Empty your lungs completely
# 2. Breathe in quietly through nose for 4 seconds
# 3. Hold breath for 7 seconds
# 4. Exhale completely through mouth for 8 seconds
# 5. Repeat 4 times"""

# def mental_health_resources():
#     return """üìö Helpful Resources:
# ‚Ä¢ Crisis Hotline: 1-800-273-TALK (8255)
# ‚Ä¢ Anxiety & Depression Association of America: adaa.org
# ‚Ä¢ National Suicide Prevention Lifeline: 988lifeline.org
# ‚Ä¢ Calm Meditation App: calm.com
# ‚Ä¢ Headspace Meditation: headspace.com"""

# # Enhanced Response Generation
# def generate_response(user_input):
#     # Analyze sentiment
#     mood = analyze_sentiment(user_input)
#     track_mood(mood)
#     st.session_state.current_mood = mood
    
#     # Add context to prompt
#     context = f"User mood detected as {mood}. Respond with empathy and emotional support."
#     full_prompt = f"{context}\nUser: {user_input}"
    
#     st.session_state.conversation_history.append({"role": "user", "content": full_prompt})
    
#     response = ollama.chat(model="llama3:8b", messages=st.session_state.conversation_history)
#     ai_response = response['message']['content']
    
#     st.session_state.conversation_history.append({"role": "assistant", "content": ai_response})
#     return ai_response

# # Define the functions for affirmation and meditation guide
# def generate_affirmation():
#     prompt = f"Provide a positive affirmation for someone feeling {st.session_state.current_mood}"
#     response = ollama.chat(model="llama3:8b", messages=[{"role": "user", "content": prompt}])
#     return response['message']['content']

# def generate_meditation_guide():
#     prompt = f"Create a 5-minute guided meditation script for someone feeling {st.session_state.current_mood}"
#     response = ollama.chat(model="llama3:8b", messages=[{"role": "user", "content": prompt}])
#     return response['message']['content']

# # Function to listen to the microphone and convert speech to text
# def listen_to_microphone():
#     recognizer = sr.Recognizer()
#     with sr.Microphone() as source:
#         st.info("Listening... Please speak now.")
#         audio = recognizer.listen(source)
#         try:
#             text = recognizer.recognize_google(audio)
#             st.success(f"You said: {text}")
#             return text
#         except sr.UnknownValueError:
#             st.error("Sorry, I did not understand that. Please try again.")
#         except sr.RequestError:
#             st.error("Could not request results from Google Speech Recognition service.")
#     return None

# # UI Components
# st.title("Mental Health Support Agent üåà")

# # Sidebar for additional features
# with st.sidebar:
#     st.header("Additional Features")
    
#     # Mood Tracking
#     with st.expander("Track Your Mood"):
#         mood = st.selectbox("How are you feeling?", ["üòÑ Happy", "üòä Calm", "üòü Sad", "üòî Stressed"])
#         if st.button("Log Mood"):
#             track_mood(mood)
#             st.success("Mood logged successfully!")
    
#     # Breathing Exercises
#     if st.button("üßò Breathing Exercise"):
#         st.info(breathing_exercise())
    
#     # Mental Health Resources
#     if st.button("üìö Get Resources"):
#         st.info(mental_health_resources())

# # Main Chat Interface
# with st.container():
#     st.subheader("Chat Interface")
    
#     # Chat history
#     with st.container():
#         st.markdown("<div class='chat-box'>", unsafe_allow_html=True)
#         for msg in st.session_state.conversation_history:
#             role = "user" if msg['role'] == "user" else "assistant"
#             with st.chat_message(role):
#                 st.write(msg['content'])
#         st.markdown("</div>", unsafe_allow_html=True)
    
#     # User input via text or microphone
#     user_message = st.chat_input("How can I help you today?")
    
#     if user_message:
#         with st.spinner("Analyzing and responding..."):
#             ai_response = generate_response(user_message)
#             with st.chat_message("assistant"):
#                 st.write(ai_response)
#                 st.caption(f"Detected Mood: {st.session_state.current_mood}")
    
#     # Custom Microphone Icon Button
#     mic_icon_url = "/Users/yashpratapsingh/Downloads/voice.svg"  # Replace this URL with the URL of your custom mic icon image
#     mic_button_html = f"""
#     <button class="microphone-button" onclick="window.streamlitApi.triggerStreamlitEvent('microphone_click')">
#         <img src="{mic_icon_url}" alt="Microphone Icon">
#     </button>
#     """
    
#     st.markdown(mic_button_html, unsafe_allow_html=True)

#     # Get the query parameters to detect if the microphone button was clicked
#     if 'microphone_click' in st.query_params:
#         speech_input = listen_to_microphone()
#         if speech_input:
#             ai_response = generate_response(speech_input)
#             with st.chat_message("assistant"):
#                 st.write(ai_response)
#                 st.caption(f"Detected Mood: {st.session_state.current_mood}")

#     # Clear Chat Button (added to the main chat interface)
#     if st.button("üßπ Clear Chat"):
#         st.session_state.conversation_history = []  # Clears the conversation history
#         st.session_state.mood_history = []  # Clears the mood history
#         st.experimental_rerun()  # Refreshes the app

# # Mood Tracking Visualization
# if st.session_state.mood_history:
#     with st.expander("View Mood History"):
#         mood_df = pd.DataFrame(st.session_state.mood_history)
#         mood_df['timestamp'] = pd.to_datetime(mood_df['timestamp'])
        
#         # Count occurrences of each mood and plot as a bar chart
#         mood_counts = mood_df['mood'].value_counts()
#         st.bar_chart(mood_counts)

# # Action Buttons
# with st.container():
#     col1, col2, col3 = st.columns(3)
    
#     with col1:
#         if st.button("üåü Get Affirmation"):
#             affirmation = generate_affirmation()
#             st.info(f"**Affirmation:** {affirmation}")
    
#     with col2:
#         if st.button("üßò Guided Meditation"):
#             meditation_guide = generate_meditation_guide()
#             st.info(f"**Meditation Guide:** {meditation_guide}")
    
#     with col3:
#         if st.button("‚ÑπÔ∏è Current Mood"):
#             st.info(f"Your current mood: {st.session_state.current_mood}")


# import streamlit as st
# import ollama
# import base64
# from textblob import TextBlob
# import nltk
# from datetime import datetime
# import pandas as pd
# import time
# import speech_recognition as sr

# # ... [Keep all the initial imports and setup code the same] ...

# # Enhanced CSS Styling
# st.markdown(f"""
#     <style>
#         .stApp {{
#             background-image: url("data:image/png;base64,{bin_str}");
#             background-size: cover;
#             background-position: center;
#         }}
        
#         /* Professional Chat Container */
#         .chat-container {{
#             max-width: 800px;
#             margin: 0 auto;
#             background: rgba(255, 255, 255, 0.95);
#             border-radius: 15px;
#             box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
#             padding: 2rem;
#         }}
        
#         /* User Message Styling */
#         .user-message {{
#             background: #e3f2fd;
#             border-radius: 15px 15px 0 15px;
#             padding: 1rem;
#             margin: 0.5rem 0;
#             max-width: 70%;
#             margin-left: auto;
#         }}
        
#         /* Bot Message Styling */
#         .bot-message {{
#             background: #f5f5f5;
#             border-radius: 15px 15px 15px 0;
#             padding: 1rem;
#             margin: 0.5rem 0;
#             max-width: 70%;
#         }}
        
#         /* Enhanced Input Area */
#         .input-container {{
#             position: fixed;
#             bottom: 2rem;
#             left: 50%;
#             transform: translateX(-50%);
#             width: 80%;
#             background: white;
#             padding: 1rem;
#             border-radius: 25px;
#             box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
#         }}
        
#         /* Professional Button Styling */
#         .stButton>button {{
#             border-radius: 20px;
#             padding: 0.5rem 1.5rem;
#             transition: all 0.3s ease;
#         }}
        
#         .stButton>button:hover {{
#             transform: translateY(-2px);
#             box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
#         }}
        
#         /* Mood Chart Container */
#         .mood-chart {{
#             background: white;
#             padding: 1.5rem;
#             border-radius: 15px;
#             margin-top: 2rem;
#         }}
#     </style>
# """, unsafe_allow_html=True)

# # ... [Keep the existing session state and function definitions] ...

# # Enhanced UI Components
# st.title("Mental Health Support Companion üå±")

# # Professional Sidebar
# with st.sidebar:
#     st.markdown("""
#         <div style='border-bottom: 2px solid #e0e0e0; padding-bottom: 1rem; margin-bottom: 2rem;'>
#             <h2 style='color: #2c3e50;'>Wellness Toolkit üß∞</h2>
#         </div>
#     """, unsafe_allow_html=True)
    
#     # Mood Tracking with Emoji Picker
#     with st.expander("üìÖ Mood Tracker", expanded=True):
#         mood_options = {
#             "üòÑ Happy": "#4CAF50",
#             "üòä Calm": "#2196F3",
#             "üòü Sad": "#FFC107",
#             "üòî Stressed": "#F44336"
#         }
#         cols = st.columns(4)
#         for i, (mood, color) in enumerate(mood_options.items()):
#             with cols[i]:
#                 if st.button(mood, key=f"mood_{i}"):
#                     track_mood(mood)
#                     st.success(f"Logged: {mood}")
    
#     # Interactive Breathing Exercise
#     with st.expander("üå¨Ô∏è Breathing Exercise"):
#         st.markdown("""
#             <div style='background: #f8f9fa; padding: 1rem; border-radius: 10px;'>
#                 <h4>4-7-8 Technique</h4>
#                 <p style='color: #666;'>Follow the animated guide:</p>
#                 <div style='display: flex; justify-content: center;'>
#                     <div style='animation: breath 8s infinite; width: 50px; height: 50px; background: #2196F3; border-radius: 50%;'></div>
#                 </div>
#             </div>
#             <style>
#                 @keyframes breath {{
#                     0% {{ transform: scale(0.8); }}
#                     25% {{ transform: scale(1.2); }}
#                     50% {{ transform: scale(0.8); }}
#                     75% {{ transform: scale(1.2); }}
#                     100% {{ transform: scale(0.8); }}
#                 }}
#             </style>
#         """, unsafe_allow_html=True)
    
#     # Enhanced Resources Section
#     with st.expander("üìö Resources"):
#         st.markdown("""
#             <div style='background: #f8f9fa; padding: 1rem; border-radius: 10px;'>
#                 <h4>Immediate Help</h4>
#                 <ul style='list-style: none; padding-left: 0;'>
#                     <li>üÜò Crisis Hotline: 1-800-273-TALK</li>
#                     <li>üåê 988lifeline.org</li>
#                 </ul>
#                 <h4>Self-Care Tools</h4>
#                 <ul style='list-style: none; padding-left: 0;'>
#                     <li>üßò Calm App</li>
#                     <li>üì± Headspace</li>
#                 </ul>
#             </div>
#         """, unsafe_allow_html=True)

# # Main Chat Interface
# with st.container():
#     st.markdown("<div class='chat-container'>", unsafe_allow_html=True)
    
#     # Chat History with Enhanced Styling
#     for msg in st.session_state.conversation_history:
#         if msg['role'] == "user":
#             st.markdown(f"""
#                 <div class='user-message'>
#                     <div style='color: #1a237e; font-weight: 500;'>You</div>
#                     <div style='margin-top: 0.5rem;'>{msg['content']}</div>
#                 </div>
#             """, unsafe_allow_html=True)
#         else:
#             st.markdown(f"""
#                 <div class='bot-message'>
#                     <div style='color: #0d47a1; font-weight: 500;'>Companion</div>
#                     <div style='margin-top: 0.5rem;'>{msg['content']}</div>
#                     <div style='font-size: 0.8rem; color: #666; margin-top: 0.5rem;'>
#                         Mood Detected: {st.session_state.current_mood}
#                     </div>
#                 </div>
#             """, unsafe_allow_html=True)
    
#     st.markdown("</div>", unsafe_allow_html=True)

# # Enhanced Input Area
# with st.container():
#     st.markdown("<div class='input-container'>", unsafe_allow_html=True)
#     col1, col2 = st.columns([6, 1])
    
#     with col1:
#         user_input = st.text_input("Share your thoughts...", label_visibility="collapsed")
    
#     with col2:
#         st.markdown("""
#             <style>
#                 .mic-button {{
#                     background: #2196F3;
#                     color: white;
#                     border: none;
#                     border-radius: 50%;
#                     width: 40px;
#                     height: 40px;
#                     display: flex;
#                     align-items: center;
#                     justify-content: center;
#                     transition: all 0.3s ease;
#                 }}
#                 .mic-button:hover {{
#                     background: #1976D2;
#                     transform: scale(1.1);
#                 }}
#             </style>
#             <button class='mic-button' onclick="window.streamlitApi.triggerStreamlitEvent('microphone_click')">
#                 üé§
#             </button>
#         """, unsafe_allow_html=True)
    
#     st.markdown("</div>", unsafe_allow_html=True)

# # ... [Keep the remaining functionality the same] ...

# # Enhanced Mood Visualization
# if st.session_state.mood_history:
#     with st.expander("üìà Mood Analysis", expanded=True):
#         st.markdown("<div class='mood-chart'>", unsafe_allow_html=True)
#         mood_df = pd.DataFrame(st.session_state.mood_history)
#         mood_df['timestamp'] = pd.to_datetime(mood_df['timestamp'])
        
#         # Create time series chart
#         mood_df['time'] = mood_df['timestamp'].dt.strftime('%H:%M')
#         mood_chart = alt.Chart(mood_df).mark_line(point=True).encode(
#             x='time:T',
#             y=alt.Y('mood:N', sort=['üòî Stressed', 'üòü Sad', 'üòä Calm', 'üòÑ Happy']),
#             color=alt.Color('mood:N', scale=alt.Scale(
#                 domain=['üòî Stressed', 'üòü Sad', 'üòä Calm', 'üòÑ Happy'],
#                 range=['#F44336', '#FFC107', '#2196F3', '#4CAF50']
#             ))
#         ).properties(height=300)
        
#         st.altair_chart(mood_chart, use_container_width=True)
#         st.markdown("</div>", unsafe_allow_html=True)

